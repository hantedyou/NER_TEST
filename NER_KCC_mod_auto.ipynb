{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.word_proc_dataframe : 將輸入的資料作斷詞、詞性標註及NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_proc_dataframe(input_Series,\n",
    "              column_name = 'Text',\n",
    "              tt_seg = (1,10),\n",
    "              export_flag = False, \n",
    "              #tt_begin = 0,tt_end = 50,\n",
    "              output_file = \"df_test_out.csv\"):\n",
    "    \"\"\"\n",
    "        data_path(str):資料路徑(字串)\n",
    "        column_name(str):要處理的欄位名稱\n",
    "        tt_seg(tuple):起訖列數\n",
    "        export_flag(boolean):是否產出檔案\n",
    "        output_file:輸出的檔案名稱，指定為CSV檔    \n",
    "    \"\"\"\n",
    "    from ckiptagger import WS, POS, NER\n",
    "    \n",
    "    \"\"\"\n",
    "    file_type = data_path[-4:]\n",
    "    print(\"輸入檔案格式為 {}\".format(file_type))\n",
    "    if 'csv' in file_type:\n",
    "        data = pd.read_csv(data_path)\n",
    "    elif 'xls' in file_type:\n",
    "        data = pd.read_excel(data_path)\n",
    "    else:\n",
    "        #print(\"檔案須為CSV或XLS/XLSX\")\n",
    "        raise Exception(\"檔案須為CSV或XLS/XLSX\")\n",
    "        #return None\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    column_list = list(input_df.columns)\n",
    "    if column_name in column_list:\n",
    "        text = input_df[column_name]\n",
    "    else:\n",
    "        print(\"輸入欄位\\\"{input_column}\\\"不存在\\n匯入檔案欄位{i_column_name}\".format(input_column = column_name,\n",
    "                                                                       i_column_name=str(column_list)))\n",
    "        raise Exception(\"不存在此欄位名稱\")\n",
    "    \"\"\"\n",
    "    \n",
    "    #ls_Test = list(text[tt_begin:tt_end])\n",
    "    \n",
    "    ###########      debug        ###############\n",
    "    print(\"起始列數：{begin}\\n結束列數:{end}\".format(begin = (tt_seg[0]),end = tt_seg[1]))\n",
    "    print(\"列印前5筆{}\".format(input_Series[:5]))\n",
    "    #print(input_Series[:10])\n",
    "    #print(input_Series[tt_seg[0]:tt_seg[1]])\n",
    "    ###########      debug        ###############\n",
    "    ls_len = len(input_Series)\n",
    "    \n",
    "\n",
    "    ls_Test = list(input_Series[:])\n",
    "    \n",
    "    \n",
    "    if (len(ls_Test) > 0):\n",
    "        print(\"取得list，長度為：{list_len}\\n 載入 WS 資料...\".format(list_len = len(ls_Test)))\n",
    "    else:\n",
    "        raise Exception(\"資料長度為0\")\n",
    "        \n",
    "        \n",
    "    \n",
    "    ws = WS(\"./data\")\n",
    "    print(\"============================\\n 開始執行 WS\\n============================\\n\")\n",
    "    word_sentence_list = ws(ls_Test\n",
    "                                # sentence_segmentation=True, # To consider delimiters\n",
    "                                # segment_delimiter_set = {\",\", \"。\", \":\", \"?\", \"!\", \";\"}),\n",
    "                                # This is the defualt set of delimiters\n",
    "                                # recommend_dictionary = dictionary1, # words in this dictionary are encouraged\n",
    "                                # coerce_dictionary = dictionary2, # words in this dictionary are forced\n",
    "                            )\n",
    "    del ws\n",
    "    del WS\n",
    "    gc.collect()\n",
    "    print(\"============================\\n WS 完成\\n============================\\n載入 POS 資料...\")\n",
    "    \n",
    "    print(\"============================\\n 開始執行 POS \\n============================\\n\")\n",
    "    pos = POS(\"./data\")\n",
    "    pos_sentence_list = pos(word_sentence_list)\n",
    "    del pos\n",
    "    del POS\n",
    "    gc.collect()\n",
    "    print(\"============================\\n POS 完成\\n============================\\n載入NER 資料...\")\n",
    "    \n",
    "    \n",
    "    print(\"============================\\n 開始執行 NER \\n============================\\n\")\n",
    "    ner = NER(\"./data\")\n",
    "    entity_sentence_list = ner(word_sentence_list, pos_sentence_list)\n",
    "    del NER\n",
    "    del ner\n",
    "    gc.collect()\n",
    "    print(\"============================\\n NER 完成\\n============================\\n\")\n",
    "        \n",
    "    df_Test = pd.DataFrame(ls_Test,columns=[column_name])\n",
    "    df_Test['WS'] = np.array(word_sentence_list)\n",
    "    \n",
    "    ##################\n",
    "    #print(\"DEBUG\")\n",
    "    #print(pos_sentence_list[:5])\n",
    "    ##################\n",
    "    \n",
    "    df_Test['POS'] = np.array(pos_sentence_list)\n",
    "    df_Test['NER'] = np.array(entity_sentence_list)\n",
    "    print(\"============================\\n Dataframe Created \\n============================\\n\")\n",
    "    \n",
    "    if export_flag is True:\n",
    "        df_Test.to_csv(output_file)\n",
    "        print(\"File Exported!!!!!\")\n",
    "    else:\n",
    "        print(\"斷詞處理完成，不產生檔案\")\n",
    "        \n",
    "    #return df_Test,word_sentence_list,pos_sentence_list,entity_sentence_list\n",
    "    return entity_sentence_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.gen_df:產生df[\"類別\",\"NER\"]供產檔使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_df(in_list):\n",
    "    df_class_list = list()\n",
    "    df_ner_list = list()\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(in_list)):\n",
    "        for j in range(len(in_list[i])):\n",
    "            count = count +1\n",
    "            a = in_list[i].pop()\n",
    "            df_class_list.append(a[2])\n",
    "            df_ner_list.append(a[3])\n",
    "        #print(type(new_list[j]),(new_list[j]))\n",
    "    #print(count)\n",
    "    extract_df = pd.DataFrame({'類別':df_class_list,'專有名詞':df_ner_list})\n",
    "    dd_extract_df = extract_df.drop_duplicates().copy()\n",
    "    del extract_df\n",
    "    df_exp = dd_extract_df.loc[dd_extract_df['類別'].isin(['LOC','PERSON', 'ORG', 'LAW', 'EVENT','GPE'])].copy()\n",
    "    del dd_extract_df\n",
    "    df_exp_2 = df_exp[df_exp['專有名詞'].map(len) >= 2].copy()\n",
    "    del df_exp\n",
    "    return df_exp_2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.proc_seg : 自動處理NER及產生CSV檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_seg(in_df,seg_len=100):\n",
    "    #計算輸入資料長度\n",
    "    df_length = len(in_df)\n",
    "    #計算要分成幾段處理\n",
    "    seg_n = math.ceil(df_length/seg_len) \n",
    "    \n",
    "    print(\"輸入資料長度:{in_len}\\n共分成{seg}段\".format(in_len = df_length,seg = seg_n))\n",
    "    \n",
    "    obj = {}\n",
    "    for i in range(seg_n):\n",
    "        #print(i*seg_len,(i+1)*seg_len)\n",
    "        #print(df_seg_test[(i*100):(i+1)*100])\n",
    "        obj['df_'+str(i)] = in_df[(i*seg_len):(i+1)*seg_len]   \n",
    "        \n",
    "   \n",
    "    for segment in range(len(obj)):\n",
    "        \n",
    "        print(\"=======================\\t開始處理第{}段\\t===================\\n\".format(segment))\n",
    "        print(\"第{}段長度：{}\".format(('df_'+ str(segment)),len(obj['df_'+ str(segment)])))\n",
    "        \n",
    "        ########################################################################################\n",
    "        # 呼叫word_proc_dataframe，回傳NER list\n",
    "        ########################################################################################\n",
    "        \n",
    "        print(\"(segment*seg_len:{},(segment+1)*segment):{}\".format((segment*seg_len),(segment+1)*seg_len))\n",
    "        print(\"=====================================\\b呼叫word_proc_dataframe\\b=============================\\n\")\n",
    "        entity_list = word_proc_dataframe(input_Series = obj['df_'+ str(segment)],\n",
    "                            tt_seg = ((segment*seg_len),(segment+1)*seg_len),export_flag = False)\n",
    "        \n",
    "        print(\"=====================================呼叫 gen_df=============================\\n\")\n",
    "        temp_df = gen_df(entity_list)\n",
    "        temp_df.sort_values(by=['類別']).to_csv(\"D:\\python_kcc\\\\NER\\\\NER_export\\\\df_out_\" + str(segment) + \".csv\")\n",
    "        #print(type(obj['df_'+ str(segment)]))\n",
    "        print(\"===========================  第{}段處理完成 ===========================  \\n\".format(segment))\n",
    "        \n",
    "        #print(obj['df_'+ str(segment)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.讀取檔案及執行自動產檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['序號', '日期', '報別', '內容'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#讀檔\n",
    "full_path = r\"D:\\python_kcc\\NER\\剪報系統匯出-正確\\all-new(11554).xlsx\"\n",
    "df_full_text = pd.read_excel(full_path)\n",
    "df_full_text.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#選擇要的欄位\n",
    "df_seg_test = df_full_text[\"內容\"][:50]\n",
    "# 執行產檔\n",
    "proc_seg(df_seg_test,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 將所有檔案彙整成一個CSV，刪掉重複&案類別排序後匯出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "path = r'D:\\python_kcc\\NER\\NER_export' \n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=0, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111878\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>專有名詞</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>類別</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EVENT</th>\n",
       "      <td>4778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPE</th>\n",
       "      <td>14624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAW</th>\n",
       "      <td>1842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>7710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>43672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERSON</th>\n",
       "      <td>39252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         專有名詞\n",
       "類別           \n",
       "EVENT    4778\n",
       "GPE     14624\n",
       "LAW      1842\n",
       "LOC      7710\n",
       "ORG     43672\n",
       "PERSON  39252"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(frame))\n",
    "frame.groupby('類別').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37716\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>專有名詞</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>類別</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EVENT</th>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPE</th>\n",
       "      <td>3994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAW</th>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>2586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>14906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERSON</th>\n",
       "      <td>13501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         專有名詞\n",
       "類別           \n",
       "EVENT    2009\n",
       "GPE      3994\n",
       "LAW       720\n",
       "LOC      2586\n",
       "ORG     14906\n",
       "PERSON  13501"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = frame.drop_duplicates().copy()\n",
    "print(len(frame))\n",
    "frame.groupby('類別').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 匯出檔案\n",
    "frame.sort_values(by=['類別']).to_csv(\"D:\\python_kcc\\\\NER\\\\NER_export\\\\df_out_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.des"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
