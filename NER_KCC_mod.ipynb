{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ckiptagger import data_utils, construct_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.載入需要的package，定義處理資料的function \"word_proc_path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_proc_path(data_path,\n",
    "              column_name,\n",
    "              tt_seg = (1,10),\n",
    "              export_flag = False, \n",
    "              #tt_begin = 0,tt_end = 50,\n",
    "              output_file = \"df_test_out.csv\"):\n",
    "    \"\"\"\n",
    "        data_path(str):資料路徑(字串)\n",
    "        column_name(str):要處理的欄位名稱\n",
    "        tt_seg(tuple):起訖列數\n",
    "        export_flag(boolean):是否產出檔案\n",
    "        output_file:輸出的檔案名稱，指定為CSV檔    \n",
    "    \"\"\"\n",
    "    from ckiptagger import WS, POS, NER\n",
    "    \n",
    "    file_type = data_path[-4:]\n",
    "    print(\"輸入檔案格式為 {}\".format(file_type))\n",
    "    if 'csv' in file_type:\n",
    "        data = pd.read_csv(data_path)\n",
    "    elif 'xls' in file_type:\n",
    "        data = pd.read_excel(data_path)\n",
    "    else:\n",
    "        #print(\"檔案須為CSV或XLS/XLSX\")\n",
    "        raise Exception(\"檔案須為CSV或XLS/XLSX\")\n",
    "        #return None\n",
    "    \n",
    "    column_list = list(data.columns)\n",
    "    if column_name in column_list:\n",
    "        text = data[column_name]\n",
    "    else:\n",
    "        print(\"輸入欄位\\\"{input_column}\\\"不存在\\n匯入檔案欄位{i_column_name}\".format(input_column = column_name,\n",
    "                                                                       i_column_name=str(column_list)))\n",
    "        raise Exception(\"不存在此欄位名稱\")\n",
    "\n",
    "    \n",
    "    #ls_Test = list(text[tt_begin:tt_end])\n",
    "    print(\"起始列數：{begin}\\n結束列數:{end}\".format(begin = (tt_seg[0]-1),end = tt_seg[1]))\n",
    "    ls_Test = list(text[(tt_seg[0]-1):tt_seg[1]])\n",
    "    \n",
    "    \n",
    "    print(\"Got list\\n 載入 WS 資料...\")\n",
    "    ws = WS(\"./data\")\n",
    "    print(\"============================\\n 開始執行 WS\\n============================\\n\")\n",
    "    word_sentence_list = ws(ls_Test\n",
    "                                # sentence_segmentation=True, # To consider delimiters\n",
    "                                # segment_delimiter_set = {\",\", \"。\", \":\", \"?\", \"!\", \";\"}),\n",
    "                                # This is the defualt set of delimiters\n",
    "                                # recommend_dictionary = dictionary1, # words in this dictionary are encouraged\n",
    "                                # coerce_dictionary = dictionary2, # words in this dictionary are forced\n",
    "                            )\n",
    "    del ws\n",
    "    del WS\n",
    "    gc.collect()\n",
    "    print(\"============================\\n WS 完成\\n============================\\n載入 POS 資料...\")\n",
    "    \n",
    "    print(\"============================\\n 開始執行 POS \\n============================\\n\")\n",
    "    pos = POS(\"./data\")\n",
    "    pos_sentence_list = pos(word_sentence_list)\n",
    "    del pos\n",
    "    del POS\n",
    "    gc.collect()\n",
    "    print(\"============================\\n POS 完成\\n============================\\n載入NER 資料...\")\n",
    "    \n",
    "    \n",
    "    print(\"============================\\n 開始執行 NER \\n============================\\n\")\n",
    "    ner = NER(\"./data\")\n",
    "    entity_sentence_list = ner(word_sentence_list, pos_sentence_list)\n",
    "    del NER\n",
    "    del ner\n",
    "    gc.collect()\n",
    "    print(\"============================\\n NER 完成\\n============================\\n\")\n",
    "        \n",
    "    df_Test = pd.DataFrame(ls_Test,columns=[column_name])\n",
    "    df_Test['WS'] = np.array(word_sentence_list)\n",
    "    \n",
    "    ##################\n",
    "    #print(\"DEBUG\")\n",
    "    #print(pos_sentence_list[:5])\n",
    "    ##################\n",
    "    \n",
    "    df_Test['POS'] = np.array(pos_sentence_list)\n",
    "    df_Test['NER'] = np.array(entity_sentence_list)\n",
    "    print(\"============================\\n Dataframe Created \\n============================\\n\")\n",
    "    \n",
    "    if export_flag is True:\n",
    "        df_Test.to_csv(output_name)\n",
    "        print(\"File Exported!!!!!\")\n",
    "    else:\n",
    "        print(\"處理完成，不產生檔案\")\n",
    "        \n",
    "    return df_Test,word_sentence_list,pos_sentence_list,entity_sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_proc_dataframe(input_Series,\n",
    "              column_name = 'Text',\n",
    "              tt_seg = (1,10),\n",
    "              export_flag = False, \n",
    "              #tt_begin = 0,tt_end = 50,\n",
    "              output_file = \"df_test_out.csv\"):\n",
    "    \"\"\"\n",
    "        data_path(str):資料路徑(字串)\n",
    "        column_name(str):要處理的欄位名稱\n",
    "        tt_seg(tuple):起訖列數\n",
    "        export_flag(boolean):是否產出檔案\n",
    "        output_file:輸出的檔案名稱，指定為CSV檔    \n",
    "    \"\"\"\n",
    "    from ckiptagger import WS, POS, NER\n",
    "    \n",
    "    \"\"\"\n",
    "    file_type = data_path[-4:]\n",
    "    print(\"輸入檔案格式為 {}\".format(file_type))\n",
    "    if 'csv' in file_type:\n",
    "        data = pd.read_csv(data_path)\n",
    "    elif 'xls' in file_type:\n",
    "        data = pd.read_excel(data_path)\n",
    "    else:\n",
    "        #print(\"檔案須為CSV或XLS/XLSX\")\n",
    "        raise Exception(\"檔案須為CSV或XLS/XLSX\")\n",
    "        #return None\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    column_list = list(input_df.columns)\n",
    "    if column_name in column_list:\n",
    "        text = input_df[column_name]\n",
    "    else:\n",
    "        print(\"輸入欄位\\\"{input_column}\\\"不存在\\n匯入檔案欄位{i_column_name}\".format(input_column = column_name,\n",
    "                                                                       i_column_name=str(column_list)))\n",
    "        raise Exception(\"不存在此欄位名稱\")\n",
    "    \"\"\"\n",
    "    \n",
    "    #ls_Test = list(text[tt_begin:tt_end])\n",
    "    \n",
    "    ###########      debug        ###############\n",
    "    print(\"起始列數：{begin}\\n結束列數:{end}\".format(begin = (tt_seg[0]),end = tt_seg[1]))\n",
    "    print(\"列印前5筆{}\".format(input_Series[:5]))\n",
    "    #print(input_Series[:10])\n",
    "    #print(input_Series[tt_seg[0]:tt_seg[1]])\n",
    "    ###########      debug        ###############\n",
    "    ls_len = len(input_Series)\n",
    "    \n",
    "\n",
    "    ls_Test = list(input_Series[:])\n",
    "    \n",
    "    \n",
    "    if (len(ls_Test) > 0):\n",
    "        print(\"取得list，長度為：{list_len}\\n 載入 WS 資料...\".format(list_len = len(ls_Test)))\n",
    "    else:\n",
    "        raise Exception(\"資料長度為0\")\n",
    "        \n",
    "        \n",
    "    \n",
    "    ws = WS(\"./data\")\n",
    "    print(\"============================\\n 開始執行 WS\\n============================\\n\")\n",
    "    word_sentence_list = ws(ls_Test\n",
    "                                # sentence_segmentation=True, # To consider delimiters\n",
    "                                # segment_delimiter_set = {\",\", \"。\", \":\", \"?\", \"!\", \";\"}),\n",
    "                                # This is the defualt set of delimiters\n",
    "                                # recommend_dictionary = dictionary1, # words in this dictionary are encouraged\n",
    "                                # coerce_dictionary = dictionary2, # words in this dictionary are forced\n",
    "                            )\n",
    "    del ws\n",
    "    del WS\n",
    "    gc.collect()\n",
    "    print(\"============================\\n WS 完成\\n============================\\n載入 POS 資料...\")\n",
    "    \n",
    "    print(\"============================\\n 開始執行 POS \\n============================\\n\")\n",
    "    pos = POS(\"./data\")\n",
    "    pos_sentence_list = pos(word_sentence_list)\n",
    "    del pos\n",
    "    del POS\n",
    "    gc.collect()\n",
    "    print(\"============================\\n POS 完成\\n============================\\n載入NER 資料...\")\n",
    "    \n",
    "    \n",
    "    print(\"============================\\n 開始執行 NER \\n============================\\n\")\n",
    "    ner = NER(\"./data\")\n",
    "    entity_sentence_list = ner(word_sentence_list, pos_sentence_list)\n",
    "    del NER\n",
    "    del ner\n",
    "    gc.collect()\n",
    "    print(\"============================\\n NER 完成\\n============================\\n\")\n",
    "        \n",
    "    df_Test = pd.DataFrame(ls_Test,columns=[column_name])\n",
    "    df_Test['WS'] = np.array(word_sentence_list)\n",
    "    \n",
    "    ##################\n",
    "    #print(\"DEBUG\")\n",
    "    #print(pos_sentence_list[:5])\n",
    "    ##################\n",
    "    \n",
    "    df_Test['POS'] = np.array(pos_sentence_list)\n",
    "    df_Test['NER'] = np.array(entity_sentence_list)\n",
    "    print(\"============================\\n Dataframe Created \\n============================\\n\")\n",
    "    \n",
    "    if export_flag is True:\n",
    "        df_Test.to_csv(output_file)\n",
    "        print(\"File Exported!!!!!\")\n",
    "    else:\n",
    "        print(\"斷詞處理完成，不產生檔案\")\n",
    "        \n",
    "    #return df_Test,word_sentence_list,pos_sentence_list,entity_sentence_list\n",
    "    return entity_sentence_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.參數設定\n",
    "### data_path_in    :要處理的檔案名稱(建議用絕對路徑)\n",
    "### column_name_in  :要處理的欄位名稱\n",
    "### proc_seg        :要處理的資料列起訖，格式為(起，迄)，均為整數，不可為0。\n",
    "### export_flag     :是否要匯出檔案，True/False\n",
    "### output_name     :匯出的檔案名稱，預設為CSV檔。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_path_in = \"KCC_Data/KCCNews11554.csv\"\n",
    "data_path_in = \"D:\\python_kcc\\\\NER\\剪報系統匯出-正確\\\\all-new(11554).xlsx\"\n",
    "#data_path_c = 'KCC_Data/20160419-20190804-自由(985筆).xlsx'\n",
    "column_name_in = \"Text\"\n",
    "column_name_in = '內容'\n",
    "#column_name_c = \"Teddd\"\n",
    "proc_seg = (1,500)\n",
    "export_file = False\n",
    "output_name = \"mod_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輸入檔案格式為 xlsx\n",
      "起始列數：0\n",
      "結束列數:500\n",
      "Got list\n",
      " 載入 WS 資料...\n",
      "============================\n",
      " 開始執行 WS\n",
      "============================\n",
      "\n",
      "============================\n",
      " WS 完成\n",
      "============================\n",
      "載入 POS 資料...\n",
      "============================\n",
      " 開始執行 POS \n",
      "============================\n",
      "\n",
      "============================\n",
      " POS 完成\n",
      "============================\n",
      "載入NER 資料...\n",
      "============================\n",
      " 開始執行 NER \n",
      "============================\n",
      "\n",
      "============================\n",
      " NER 完成\n",
      "============================\n",
      "\n",
      "============================\n",
      " Dataframe Created \n",
      "============================\n",
      "\n",
      "處理完成，不產生檔案\n"
     ]
    }
   ],
   "source": [
    "demo_df,ws_list,pos_list,ner_list = word_proc_path(data_path = data_path_in,\n",
    "          column_name = column_name_in,\n",
    "          tt_seg = proc_seg,export_flag = export_file ,output_file=output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, set, 45)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ner_list),type(ner_list[0]),len(ner_list[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.取出NER類別及專有名詞，分別存到df_class_list 及df_ner_list中\n",
    "# 4.將其組成有兩個欄位['類別','專有名詞']的DataFrame。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_df(in_list):\n",
    "    df_class_list = list()\n",
    "    df_ner_list = list()\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(in_list)):\n",
    "        for j in range(len(in_list[i])):\n",
    "            count = count +1\n",
    "            a = in_list[i].pop()\n",
    "            df_class_list.append(a[2])\n",
    "            df_ner_list.append(a[3])\n",
    "        #print(type(new_list[j]),(new_list[j]))\n",
    "    #print(count)\n",
    "    extract_df = pd.DataFrame({'類別':df_class_list,'專有名詞':df_ner_list})\n",
    "    dd_extract_df = extract_df.drop_duplicates().copy()\n",
    "    del extract_df\n",
    "    df_exp = dd_extract_df.loc[dd_extract_df['類別'].isin(['LOC','PERSON', 'ORG', 'LAW', 'EVENT','GPE'])].copy()\n",
    "    del dd_extract_df\n",
    "    df_exp_2 = df_exp[df_exp['專有名詞'].map(len) >= 2].copy()\n",
    "    del df_exp\n",
    "    return df_exp_2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19013\n"
     ]
    }
   ],
   "source": [
    "df_class_list = list()\n",
    "df_ner_list = list()\n",
    "\n",
    "count = 0\n",
    "for i in range(len(ner_list)):\n",
    "    for j in range(len(ner_list[i])):\n",
    "        count = count +1\n",
    "        a = ner_list[i].pop()\n",
    "        df_class_list.append(a[2])\n",
    "        df_ner_list.append(a[3])\n",
    "        #print(type(new_list[j]),(new_list[j]))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_df = pd.DataFrame(\n",
    "{'類別':df_class_list,\n",
    " '專有名詞':df_ner_list\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.檢視DataFrame資訊，查看各類別分別有多少資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           類別   專有名詞\n",
      "count   19013  19013\n",
      "unique     18   6653\n",
      "top       ORG     高雄\n",
      "freq     4170    784\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>專有名詞</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>類別</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CARDINAL</th>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <td>2412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EVENT</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAC</th>\n",
       "      <td>806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPE</th>\n",
       "      <td>3478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LANGUAGE</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAW</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MONEY</th>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NORP</th>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORDINAL</th>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>4170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERCENT</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERSON</th>\n",
       "      <td>3679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRODUCT</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUANTITY</th>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIME</th>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WORK_OF_ART</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             專有名詞\n",
       "類別               \n",
       "CARDINAL     1894\n",
       "DATE         2412\n",
       "EVENT         302\n",
       "FAC           806\n",
       "GPE          3478\n",
       "LANGUAGE       37\n",
       "LAW            71\n",
       "LOC           572\n",
       "MONEY         363\n",
       "NORP          203\n",
       "ORDINAL       363\n",
       "ORG          4170\n",
       "PERCENT        75\n",
       "PERSON       3679\n",
       "PRODUCT        11\n",
       "QUANTITY      243\n",
       "TIME          291\n",
       "WORK_OF_ART    43"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(extract_df.describe())\n",
    "extract_df.groupby('類別').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6-1.DataFrame處理 ─ 刪除重複資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19013, 6875)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd_extract_df = extract_df.drop_duplicates()\n",
    "len(extract_df),len(dd_extract_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6-2.DataFrame處理 ─ 挑出需要匯出的類別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FAC', 'ORDINAL', 'GPE', 'ORG', 'PERSON', 'MONEY', 'DATE',\n",
       "       'PERCENT', 'LOC', 'TIME', 'NORP', 'CARDINAL', 'LANGUAGE', 'LAW',\n",
       "       'EVENT', 'QUANTITY', 'WORK_OF_ART', 'PRODUCT'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd_extract_df['類別'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3984"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exp = dd_extract_df.loc[dd_extract_df['類別'].isin(['LOC','PERSON', 'ORG', 'LAW', 'EVENT','GPE'])]\n",
    "len(df_exp)\n",
    "#https://stackoverflow.com/questions/17071871/how-to-select-rows-from-a-dataframe-based-on-column-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6-3.DataFrame處理 ─ 刪掉長度小於2的專有名詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3918"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exp_2 = df_exp[df_exp['專有名詞'].map(len) >= 2].copy()\n",
    "len(df_exp_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>類別</th>\n",
       "      <th>專有名詞</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPE</td>\n",
       "      <td>台灣</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORG</td>\n",
       "      <td>文化部長</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ORG</td>\n",
       "      <td>衛武營藝術文化中心</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ORG</td>\n",
       "      <td>高雄大東文化藝術中心</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PERSON</td>\n",
       "      <td>洪孟啟</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       類別        專有名詞\n",
       "2     GPE          台灣\n",
       "3     ORG        文化部長\n",
       "5     ORG   衛武營藝術文化中心\n",
       "6     ORG  高雄大東文化藝術中心\n",
       "7  PERSON         洪孟啟"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exp_2[:5].sort_values(by=['類別'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.將轉出的類別及專有名詞匯出成CSV檔\n",
    "### (1)路徑：\\\\NER\\\\NER_export\n",
    "### (2)檔案命名： NER_rlt_來源檔名_起始列數_結尾列數\n",
    "### EX：來源檔名為KCCNews11554，本次處理的起訖列數為1~100\n",
    "###     則檔名為 NER_rlt_KCCNews11554_1_100.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_NER_file_name =  \"NER_rlt_all-new_1_500\"\n",
    "df_exp_2.sort_values(by=['類別']).to_csv(\"D:\\python_kcc\\\\NER\\\\NER_export\\\\\" + ex_NER_file_name + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 直接抓檔案來分段處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_path = r\"D:\\python_kcc\\NER\\剪報系統匯出-正確\\all-new(11554).xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_text = pd.read_excel(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['序號', '日期', '報別', '內容'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_text.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seg_test = df_full_text['內容'][:323]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.series.Series,\n",
       " 0    馬英九總統昨天上午視察衛武營藝術文化中心，文化部長洪孟啟、工程會副主委顏久榮及高雄市副市長吳...\n",
       " 1    　日本九州熊本縣接連遭強震襲擊，台灣分別捐贈熊本縣政府和日本政府款項，高雄市長陳菊、台南市 ...\n",
       " 2    　壽山動物園為增進動物飼養福祉及保育工作，特設立「高雄市壽山動物園認養辦法」設立動物認養專戶...\n",
       " 3    日本九州熊本地震災情慘重，高雄市長陳菊昨天說，她將率先捐出一月所得；她同時指示市府相關單位 ...\n",
       " 4    睽違超過半世紀，緬甸官方代表一行人，包含三位緬甸聯邦議會議員、美國農村發展組織及緬甸農業領袖...\n",
       " Name: 內容, dtype: object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_seg_test),df_seg_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "obj = {}\n",
    "for i in range(4):\n",
    "    print(i)\n",
    "    #print(i*seg_len,(i+1)*seg_len)\n",
    "        #print(df_seg_test[(i*100):(i+1)*100])\n",
    "    obj['df_'+str(i)] = df_seg_test[(i*100):(i+1)*100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj['df_0'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_seg(in_df,seg_len=100):\n",
    "    #計算輸入資料長度\n",
    "    df_length = len(in_df)\n",
    "    #計算要分成幾段處理\n",
    "    seg_n = math.ceil(df_length/seg_len) \n",
    "    \n",
    "    print(\"輸入資料長度:{in_len}\\n共分成{seg}段\".format(in_len = df_length,seg = seg_n))\n",
    "    \n",
    "    obj = {}\n",
    "    for i in range(seg_n):\n",
    "        #print(i*seg_len,(i+1)*seg_len)\n",
    "        #print(df_seg_test[(i*100):(i+1)*100])\n",
    "        obj['df_'+str(i)] = in_df[(i*seg_len):(i+1)*seg_len]   \n",
    "        \n",
    "   \n",
    "    for segment in range(len(obj)):\n",
    "        \n",
    "        print(\"=======================\\t開始處理第{}段\\t===================\\n\".format(segment))\n",
    "        print(\"第{}段長度：{}\".format(('df_'+ str(segment)),len(obj['df_'+ str(segment)])))\n",
    "        \n",
    "        ########################################################################################\n",
    "        # 呼叫word_proc_dataframe，回傳NER list\n",
    "        ########################################################################################\n",
    "        \n",
    "        print(\"(segment*seg_len:{},(segment+1)*segment):{}\".format((segment*seg_len),(segment+1)*seg_len))\n",
    "        print(\"=====================================\\b呼叫word_proc_dataframe\\b=============================\\n\")\n",
    "        entity_list = word_proc_dataframe(input_Series = obj['df_'+ str(segment)],\n",
    "                            tt_seg = ((segment*seg_len),(segment+1)*seg_len),export_flag = False)\n",
    "        \n",
    "        print(\"=====================================呼叫 gen_df=============================\\n\")\n",
    "        temp_df = gen_df(entity_list)\n",
    "        temp_df.sort_values(by=['類別']).to_csv(\"D:\\python_kcc\\\\NER\\\\NER_export\\\\df_out_\" + str(segment) + \".csv\")\n",
    "        #print(type(obj['df_'+ str(segment)]))\n",
    "        print(\"===========================\\b第{}段處理完成\\n================================================\".format(segment))\n",
    "        \n",
    "        #print(obj['df_'+ str(segment)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proc_seg(df_seg_test,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(1100/500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.floor(1100/500) + 1100%500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_length = 1536\n",
    "seg_n = math.ceil(df_length/500)\n",
    "seg_n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
