{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 引入package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ckiptagger import WS, POS, NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_proc_dataframe(input_Series,\n",
    "              column_name = 'Text',\n",
    "              tt_seg = (1,10),\n",
    "              export_flag = False, \n",
    "              #tt_begin = 0,tt_end = 50,\n",
    "              output_file = \"df_test_out.csv\"):\n",
    "    \"\"\"\n",
    "        data_path(str):資料路徑(字串)\n",
    "        column_name(str):要處理的欄位名稱\n",
    "        tt_seg(tuple):起訖列數\n",
    "        export_flag(boolean):是否產出檔案\n",
    "        output_file:輸出的檔案名稱，指定為CSV檔    \n",
    "    \"\"\"\n",
    "    from ckiptagger import WS, POS, NER\n",
    "    \n",
    "    \"\"\"\n",
    "    file_type = data_path[-4:]\n",
    "    print(\"輸入檔案格式為 {}\".format(file_type))\n",
    "    if 'csv' in file_type:\n",
    "        data = pd.read_csv(data_path)\n",
    "    elif 'xls' in file_type:\n",
    "        data = pd.read_excel(data_path)\n",
    "    else:\n",
    "        #print(\"檔案須為CSV或XLS/XLSX\")\n",
    "        raise Exception(\"檔案須為CSV或XLS/XLSX\")\n",
    "        #return None\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    column_list = list(input_df.columns)\n",
    "    if column_name in column_list:\n",
    "        text = input_df[column_name]\n",
    "    else:\n",
    "        print(\"輸入欄位\\\"{input_column}\\\"不存在\\n匯入檔案欄位{i_column_name}\".format(input_column = column_name,\n",
    "                                                                       i_column_name=str(column_list)))\n",
    "        raise Exception(\"不存在此欄位名稱\")\n",
    "    \"\"\"\n",
    "    \n",
    "    #ls_Test = list(text[tt_begin:tt_end])\n",
    "    \n",
    "    ###########      debug        ###############\n",
    "    print(\"起始列數：{begin}\\n結束列數:{end}\".format(begin = (tt_seg[0]),end = tt_seg[1]))\n",
    "    print(\"列印前5筆{}\".format(input_Series[:5]))\n",
    "    #print(input_Series[:10])\n",
    "    #print(input_Series[tt_seg[0]:tt_seg[1]])\n",
    "    ###########      debug        ###############\n",
    "    ls_len = len(input_Series)\n",
    "    \n",
    "\n",
    "    ls_Test = list(input_Series[:])\n",
    "    \n",
    "    \n",
    "    if (len(ls_Test) > 0):\n",
    "        print(\"取得list，長度為：{list_len}\\n 載入 WS 資料...\".format(list_len = len(ls_Test)))\n",
    "    else:\n",
    "        raise Exception(\"資料長度為0\")\n",
    "        \n",
    "        \n",
    "    \n",
    "    ws = WS(\"./data\")\n",
    "    print(\"============================\\n 開始執行 WS\\n============================\\n\")\n",
    "    word_sentence_list = ws(ls_Test\n",
    "                                # sentence_segmentation=True, # To consider delimiters\n",
    "                                # segment_delimiter_set = {\",\", \"。\", \":\", \"?\", \"!\", \";\"}),\n",
    "                                # This is the defualt set of delimiters\n",
    "                                # recommend_dictionary = dictionary1, # words in this dictionary are encouraged\n",
    "                                # coerce_dictionary = dictionary2, # words in this dictionary are forced\n",
    "                            )\n",
    "    del ws\n",
    "    del WS\n",
    "    gc.collect()\n",
    "    print(\"============================\\n WS 完成\\n============================\\n載入 POS 資料...\")\n",
    "    \n",
    "    print(\"============================\\n 開始執行 POS \\n============================\\n\")\n",
    "    pos = POS(\"./data\")\n",
    "    pos_sentence_list = pos(word_sentence_list)\n",
    "    del pos\n",
    "    del POS\n",
    "    gc.collect()\n",
    "    print(\"============================\\n POS 完成\\n============================\\n載入NER 資料...\")\n",
    "    \n",
    "    \n",
    "    print(\"============================\\n 開始執行 NER \\n============================\\n\")\n",
    "    ner = NER(\"./data\")\n",
    "    entity_sentence_list = ner(word_sentence_list, pos_sentence_list)\n",
    "    del NER\n",
    "    del ner\n",
    "    gc.collect()\n",
    "    print(\"============================\\n NER 完成\\n============================\\n\")\n",
    "        \n",
    "    df_Test = pd.DataFrame(ls_Test,columns=[column_name])\n",
    "    df_Test['WS'] = np.array(word_sentence_list)\n",
    "    \n",
    "    ##################\n",
    "    #print(\"DEBUG\")\n",
    "    #print(pos_sentence_list[:5])\n",
    "    ##################\n",
    "    \n",
    "    df_Test['POS'] = np.array(pos_sentence_list)\n",
    "    df_Test['NER'] = np.array(entity_sentence_list)\n",
    "    print(\"============================\\n Dataframe Created \\n============================\\n\")\n",
    "    \n",
    "    if export_flag is True:\n",
    "        df_Test.to_csv(output_file)\n",
    "        print(\"File Exported!!!!!\")\n",
    "    else:\n",
    "        print(\"斷詞處理完成，不產生檔案\")\n",
    "        \n",
    "    #return df_Test,word_sentence_list,pos_sentence_list,entity_sentence_list\n",
    "    return entity_sentence_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_proc_path_all(data_path,\n",
    "              column_name,\n",
    "              #tt_seg = (1,10),\n",
    "              export_flag = False, \n",
    "              #tt_begin = 0,tt_end = 50,\n",
    "              output_file = \"df_test_out.csv\"):\n",
    "    \"\"\"\n",
    "        ===============================\n",
    "        108.12.10 改為不用輸入起訖列數\n",
    "        ===============================\n",
    "        \n",
    "        \n",
    "        data_path(str):資料路徑(字串)\n",
    "        column_name(str):要處理的欄位名稱\n",
    "        tt_seg(tuple):起訖列數\n",
    "        export_flag(boolean):是否產出檔案\n",
    "        output_file:輸出的檔案名稱，指定為CSV檔    \n",
    "    \"\"\"\n",
    "    from ckiptagger import WS, POS, NER\n",
    "    \n",
    "    file_type = data_path[-4:]\n",
    "    print(\"輸入檔案格式為 {}\".format(file_type))\n",
    "    if 'csv' in file_type:\n",
    "        data = pd.read_csv(data_path)\n",
    "    elif 'xls' in file_type:\n",
    "        data = pd.read_excel(data_path)\n",
    "    else:\n",
    "        #print(\"檔案須為CSV或XLS/XLSX\")\n",
    "        raise Exception(\"檔案須為CSV或XLS/XLSX\")\n",
    "        #return None\n",
    "    \n",
    "    column_list = list(data.columns)\n",
    "    if column_name in column_list:\n",
    "        text = data[column_name]\n",
    "    else:\n",
    "        print(\"輸入欄位\\\"{input_column}\\\"不存在\\n匯入檔案欄位{i_column_name}\".format(input_column = column_name,\n",
    "                                                                       i_column_name=str(column_list)))\n",
    "        raise Exception(\"不存在此欄位名稱\")\n",
    "\n",
    "    \n",
    "    #ls_Test = list(text[tt_begin:tt_end])\n",
    "    #print(\"起始列數：{begin}\\n結束列數:{end}\".format(begin = (tt_seg[0]-1),end = tt_seg[1]))\n",
    "    #ls_Test = list(text[(tt_seg[0]-1):tt_seg[1]])\n",
    "    ls_Test = list(text)\n",
    "    \n",
    "    if (len(ls_Test) > 0):\n",
    "        print(\"取得list，長度為：{list_len}\\n 載入 WS 資料...\".format(list_len = len(ls_Test)))\n",
    "    else:\n",
    "        raise Exception(\"資料長度為0\")\n",
    "    \n",
    "    \n",
    "    print(\"Got list\\n 載入 WS 資料...\")\n",
    "    ws = WS(\"./data\")\n",
    "    print(\"============================\\n 開始執行 WS\\n============================\\n\")\n",
    "    word_sentence_list = ws(ls_Test\n",
    "                                # sentence_segmentation=True, # To consider delimiters\n",
    "                                # segment_delimiter_set = {\",\", \"。\", \":\", \"?\", \"!\", \";\"}),\n",
    "                                # This is the defualt set of delimiters\n",
    "                                # recommend_dictionary = dictionary1, # words in this dictionary are encouraged\n",
    "                                # coerce_dictionary = dictionary2, # words in this dictionary are forced\n",
    "                            )\n",
    "    del ws\n",
    "    del WS\n",
    "    gc.collect()\n",
    "    print(\"============================\\n WS 完成\\n============================\\n載入 POS 資料...\")\n",
    "    \n",
    "    print(\"============================\\n 開始執行 POS \\n============================\\n\")\n",
    "    pos = POS(\"./data\")\n",
    "    pos_sentence_list = pos(word_sentence_list)\n",
    "    del pos\n",
    "    del POS\n",
    "    gc.collect()\n",
    "    print(\"============================\\n POS 完成\\n============================\\n載入NER 資料...\")\n",
    "    \n",
    "    \n",
    "    print(\"============================\\n 開始執行 NER \\n============================\\n\")\n",
    "    ner = NER(\"./data\")\n",
    "    entity_sentence_list = ner(word_sentence_list, pos_sentence_list)\n",
    "    del NER\n",
    "    del ner\n",
    "    gc.collect()\n",
    "    print(\"============================\\n NER 完成\\n============================\\n\")\n",
    "        \n",
    "    df_Test = pd.DataFrame(ls_Test,columns=[column_name])\n",
    "    df_Test['WS'] = np.array(word_sentence_list)\n",
    "    \n",
    "    ##################\n",
    "    #print(\"DEBUG\")\n",
    "    #print(pos_sentence_list[:5])\n",
    "    ##################\n",
    "    \n",
    "    df_Test['POS'] = np.array(pos_sentence_list)\n",
    "    df_Test['NER'] = np.array(entity_sentence_list)\n",
    "    print(\"============================\\n Dataframe Created \\n============================\\n\")\n",
    "    \n",
    "    if export_flag is True:\n",
    "        df_Test.to_excel(output_file)\n",
    "        print(\"File Exported!!!!!\")\n",
    "    else:\n",
    "        print(\"處理完成，不產生檔案\")\n",
    "        \n",
    "    return df_Test,word_sentence_list,pos_sentence_list,entity_sentence_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 讀檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['序號', '日期', '報別', '內容'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = r\"D:\\python_kcc\\NER\\剪報系統匯出-正確\\all-new(11554).xlsx\"\n",
    "full_data = pd.read_excel(data_path)\n",
    "full_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11554, pandas.core.series.Series)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_columns = full_data['內容'] #這邊取出就變成Series\n",
    "len(df_columns),type(df_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ls_Test = list(text[200:250])\n",
    "#df_Test = pd.DataFrame(ls_Test,columns=[\"Text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 抽樣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11434    直球對決！高雄市長選情白熱化，民進黨籍高雄市長候選人陳其邁與國民黨籍高雄市長候選人韓國瑜終於...\n",
       "10283    伊甸基金會在高市鳳山區成立「溫馨家園」昨開幕，提供十六到六十四歲身心障礙者日間照顧服務，訓練...\n",
       "8921     台北市政府年底不再與救國團劍潭青年活動中心續約，包括高雄市及新北市也有土地租給救國團的青年活...\n",
       "7889     唐晞宇（高雄市，經理） 政府不應該當鴕鳥，公布液化土壤區域是好事，我支持這種作法，讓民眾可瞭...\n",
       "710      　最近是全台各企業、機關團體舉行年度尾牙旺季，高雄市各飯店、餐廳都接到尾牙訂單，但不少飯店、...\n",
       "Name: 內容, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample_columns = df_columns.sample(n=100).copy()\n",
    "sample_columns[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_name = \"df_sample_108121002\"\n",
    "sample_columns.to_excel(r\"D:\\python_kcc\\NER\\NER_export\\\\\" + output_file_name + \".xls\",header=['內容'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = (r\"D:\\python_kcc\\NER\\NER_export\\\\\" + output_file_name + \".xls\")\n",
    "in_data = pd.read_excel(data_path,index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame,\n",
       " 100,\n",
       "                                                       內容\n",
       " 11434  直球對決！高雄市長選情白熱化，民進黨籍高雄市長候選人陳其邁與國民黨籍高雄市長候選人韓國瑜終於...\n",
       " 10283  伊甸基金會在高市鳳山區成立「溫馨家園」昨開幕，提供十六到六十四歲身心障礙者日間照顧服務，訓練...\n",
       " 8921   台北市政府年底不再與救國團劍潭青年活動中心續約，包括高雄市及新北市也有土地租給救國團的青年活...\n",
       " 7889   唐晞宇（高雄市，經理） 政府不應該當鴕鳥，公布液化土壤區域是好事，我支持這種作法，讓民眾可瞭...\n",
       " 710    　最近是全台各企業、機關團體舉行年度尾牙旺季，高雄市各飯店、餐廳都接到尾牙訂單，但不少飯店、...)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(in_data),len(in_data),in_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輸入檔案格式為 .xls\n",
      "取得list，長度為：100\n",
      " 載入 WS 資料...\n",
      "Got list\n",
      " 載入 WS 資料...\n",
      "============================\n",
      " 開始執行 WS\n",
      "============================\n",
      "\n",
      "============================\n",
      " WS 完成\n",
      "============================\n",
      "載入 POS 資料...\n",
      "============================\n",
      " 開始執行 POS \n",
      "============================\n",
      "\n",
      "============================\n",
      " POS 完成\n",
      "============================\n",
      "載入NER 資料...\n",
      "============================\n",
      " 開始執行 NER \n",
      "============================\n",
      "\n",
      "============================\n",
      " NER 完成\n",
      "============================\n",
      "\n",
      "============================\n",
      " Dataframe Created \n",
      "============================\n",
      "\n",
      "File Exported!!!!!\n"
     ]
    }
   ],
   "source": [
    "demo_df,ws_list,pos_list,ner_list = word_proc_path_all(data_path = data_path,\n",
    "          column_name = \"內容\",\n",
    "          export_flag = True,output_file = \"sample_NER_rlt_108121002.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"sample_NER_rlt_1081210.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = gen_df(demo_df['NER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\u3000', '由', '高市府', '社會局長', '青', '綜合', '服務', '中心', '主辦', '、', '社團', '法人', '高雄市', '夢想', '城市', '發展', '協會', '承辦', '的', '長青', '學苑', '，', '為', '迎接', '新', ' ', '學期', '到來', '，', '七日', '起', '至', '十一日', '，', '在', '長青', '中心', '一樓', '大廳', '舉辦', '開學', '迎新週', '活動', '，', '邀請到', '多', '位', '師生', '表演', '拿手', '才藝', '，', '讓', '初次', '上課', '的', '學員', '一', '次', '看', ' ', '夠本', '。', ' ', '長青', '學苑', '一百零五年度', '課程', '自', '七日', '起', '陸續', '展開', '，', '今年', '數千', '名', '學員', '中', '，', '以', '九十八', '歲', '的', '王阿有', '為', '最', '高齡', '，', '他', '在', '長青', '學苑', '的', '學習', '資歷', '與', '長', ' 青', '中心', '歷史', '相仿', '，', '已', '近', '二十', '年', '，', '向來', '獨鍾', '「', '元極舞班', '」', '，', '再', '加上', '每', '天', '到', '長青', '中心', '健身室', '報到', '，', '即便', '年歲', '已', '高', '，', '卻', '仍', '像', '一', '尾', '活龍', '，', '真 正', '的', '老當益壯', '。', ' \\u3000', '這', '次', '開學', '迎新', '週', '規劃', '一', '系列', '精彩', '活動', '，', '希望', '在', '學期', '開始', '讓', '大家', '耳目一新', '，', '活動', '高潮', '是', '在', '開學', '週尾聲', '邀請', '高雄', '郵局', '共襄盛舉', '。', '今年', ' ', '適逢', '中華', '郵政', '一百二十', '週年', '，', '高雄', '郵局長', '郭同志', '帶領', '同仁', '於', '郵政節', '前夕', '假', '長青', '中心', '舉辦', '慶生', '活動', '，', '與', '社會局', '副局長', '謝琍琍', '、', '長青', '中', ' 心', '主任', '劉耀元', '及', '現場', '長輩', '共同', '進行', '，', '除', '歡慶', '中華', '郵政', '一百二十', '歲', '生日快樂', '，', '也', '期許', '現場', '長輩', '健康', '活力', '呷', '百二', '！', '除', '慶祝', '儀式', '，', '長青學', ' 苑', '長輩', '們', '載歌載舞', '所', '展現', '才藝', '精彩', '萬分', '，', '郵政', '寶寶', '可愛', '逗趣', '模樣', '，', '更', '是', '吸睛度', '百分百', '，', '現場', '群眾', '個個', '搶', '著', '拍照', '，', '場面', '熱鬧', '。', ' \\u3000', '謝琍琍', '表示', '，', '長青', '學苑', '以', '「', '終身', '學習', '」', '為', '目標', '，', '是', '一', '個', '讓', '長者', '都', '能', '開心', '學習', '的', '場域', '，', '俗話說', '「', '活', '到', '老，', '學', '到', '老', '」', '，', '長青', '學苑', '將', '永', ' ', '遠', '是', '一', '個', '快樂', '學習', '及', '結交', '好友', '的', '樂園', '，', '也', '希望', '長輩', '們', '協助', '宣傳', '，', '讓', '更多', '銀髮族', '擁有', '健康', '充實', '的', '退休', '生活', '。']\n"
     ]
    }
   ],
   "source": [
    "print(ws_list[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_df(in_list):\n",
    "    df_class_list = list()\n",
    "    df_ner_list = list()\n",
    "    \n",
    "    proc_list = in_list.copy()\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(in_list)):\n",
    "        for j in range(len(in_list[i])):\n",
    "            count = count +1\n",
    "            a = in_list[i].pop()\n",
    "            df_class_list.append(a[2])\n",
    "            df_ner_list.append(a[3])\n",
    "        #print(type(new_list[j]),(new_list[j]))\n",
    "    #print(count)\n",
    "    extract_df = pd.DataFrame({'類別':df_class_list,'專有名詞':df_ner_list})\n",
    "    dd_extract_df = extract_df.drop_duplicates().copy()\n",
    "    del extract_df\n",
    "    \n",
    "    #==============================\n",
    "    # 108.12.10 拿掉類別挑選，改成全取\n",
    "    \"\"\"\n",
    "    df_exp = dd_extract_df.loc[dd_extract_df['類別'].isin(['LOC','PERSON', 'ORG', 'LAW', 'EVENT','GPE','FAC'])].copy()\n",
    "    del dd_extract_df\n",
    "    df_exp_2 = df_exp[df_exp['專有名詞'].map(len) >= 2].copy()\n",
    "    del df_exp\n",
    "    \"\"\"\n",
    "    #df_exp = dd_extract_df.loc[dd_extract_df['類別'].isin(['LOC','PERSON', 'ORG', 'LAW', 'EVENT','GPE'])].copy()\n",
    "    #del dd_extract_df\n",
    "    df_exp_2 = dd_extract_df[dd_extract_df['專有名詞'].map(len) >= 2].copy()\n",
    "    del dd_extract_df\n",
    "    \n",
    "    #==============================\n",
    "    return df_exp_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===============================\n",
    "# 測試：結巴斷詞比較\n",
    "# ==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import io\n",
    "import os.path\n",
    "import glob\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "#from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\b1194\\AppData\\Local\\Continuum\\anaconda3\\envs\\Data_Science\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "from jieba import analyse\n",
    "import string\n",
    "#from gensim.models.word2vec import Word2Vec\n",
    "#import word2vec\n",
    "import logging\n",
    "from gensim.models import word2vec\n",
    "#https://github.com/danielfrg/word2vec/blob/master/examples/word2vec.ipynb\n",
    "#https://anaconda.org/anaconda/word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入停止詞詞庫\n",
    "stopword_set = set()\n",
    "path_stop_word = r\"D:\\python_kcc\\dict\\stop_word.txt\"\n",
    "with open(path_stop_word,'r', encoding='utf-8') as stopwords:\n",
    "    for stopword in stopwords:\n",
    "        stopword_set.add(stopword.strip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11434    直球對決！高雄市長選情白熱化，民進黨籍高雄市長候選人陳其邁與國民黨籍高雄市長候選人韓國瑜終於...\n",
       "10283    伊甸基金會在高市鳳山區成立「溫馨家園」昨開幕，提供十六到六十四歲身心障礙者日間照顧服務，訓練...\n",
       "8921     台北市政府年底不再與救國團劍潭青年活動中心續約，包括高雄市及新北市也有土地租給救國團的青年活...\n",
       "7889     唐晞宇（高雄市，經理） 政府不應該當鴕鳥，公布液化土壤區域是好事，我支持這種作法，讓民眾可瞭...\n",
       "710      　最近是全台各企業、機關團體舉行年度尾牙旺季，高雄市各飯店、餐廳都接到尾牙訂單，但不少飯店、...\n",
       "Name: 內容, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_columns[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "strCut = jieba.cut(sample_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "cut_result = list()\n",
    "count = 0\n",
    "for ele in sample_columns:\n",
    "    count = count +1 \n",
    "    #print(type(ele))\n",
    "    str_o = jieba.cut(ele)\n",
    "    str_list = [word for word in str_o if word not in stopword_set]\n",
    "    strout = \" \".join(str_list)\n",
    "    \n",
    "    cut_result.append(strout)\n",
    "    #cut_result.append(pd.Series(str_list))\n",
    "    #a = pd.Series(jieba.cut(ele))\n",
    "    #print(a)\n",
    "    #cut_result.append(a)\n",
    "print(len(cut_result))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\u3000 高 市府 社會 局長 青 綜合 服務 中心 主辦 社團 法人 高雄市 夢想 城市 發展 協會 承辦 長 青學苑 迎接 新   學期 七日 十一日 長 青 中心 一樓 大廳 舉辦 開學 迎新 週活動 邀請 多位 師生 表演 拿手 才藝 初次 上課 學員 一次   夠本   長 青學苑 一百零五 年度 課程 七日 起陸續 展開 今年 數 千名 學員中 九十八 歲 王阿有 最高 齡 長 青學苑 學習 資歷 長   青 中心 歷史 相仿 已近 二十年 獨 鍾 元極 舞班 加上 每天 長 青 中心 健身 室 報到 年 歲 高 一尾 活龍 真   正 老 當益壯   \\u3000 開學 迎新 週規劃 一系列 精彩 活動 希望 學期 耳目一新 活動 高潮 開學 週尾聲 邀請 高雄 郵局 共 襄盛舉 今年   適逢 中華郵政 一百二十 週年 高雄 郵局 長 郭 同志 帶領 同仁 郵政節 前夕 假長 青 中心 舉辦慶 生活 動 社會局 副 局長 謝 琍 琍 長 青中   心 主任 劉耀元 現場 長 輩 共同 進行 歡慶 中華郵政 一百二十 歲 生日 快樂 期許 現場 長 輩 健康 活力 呷 百二 除慶祝 儀式 長 青學   苑長 輩們 載 歌載 舞所展 現才藝 精彩 萬分 郵政寶寶可愛 逗趣 模樣 更是 吸睛 度 百分百 現場 群眾 搶 拍照 場面 熱鬧   \\u3000 謝 琍 琍 表示 長 青學苑 終身 學習 目標 一個 長 開心 學習 場域 俗話 說 活到老 學到 老 長 青學苑 將永   遠是 一個 快樂學習 結交 好友 樂園 希望 長 輩們 協助 宣傳 更 銀 髮 族 擁有 健康 充實 退休 生活'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#jieba.set_dictionary(\"dict/dict.big.txt\")\n",
    "#jieba.load_userdict(\"dict/CIS_Dict.txt\")\n",
    "\n",
    "path_b_dict = r\"D:\\python_kcc\\dict\\dict/dict.big.txt\"\n",
    "path_CIS_dict = r\"D:\\python_kcc\\dict\\CIS_Dict.txt\"\n",
    "jieba.set_dictionary(path_b_dict)\n",
    "jieba.load_userdict(path_CIS_dict)\n",
    "\n",
    "\n",
    "#jieba.analyse.set_stop_words(\"dict/stop_word.txt\")\n",
    "\n",
    "csvInPath = \"export_csv/out.csv\"\n",
    "csvOutPath = \"export_csv/out2_cut_stopword.csv\"\n",
    "\n",
    "str_de = \"===================================================================\\n\"\n",
    "\n",
    "csvIn = open(csvInPath , newline='', encoding='utf-8-sig')\n",
    "rowlists = csv.reader(csvIn)\n",
    "csvOut = open(csvOutPath, \"w\", newline='', encoding='utf-8-sig')\n",
    "writer = csv.writer(csvOut)\n",
    "\n",
    "for row in rowlists:\n",
    "    str1 = row[7].replace(\"\\r\\n\", \"\").replace(\" \", \"\").replace(\"：\", \"\").replace(\"，\", \"\").replace(\"！\", \"\").replace(\"、\", \"\").replace(\"。\", \"\")\n",
    "    str1 = str1.replace(\"「\", \"\").replace(\"」\", \"\").replace(\"？\", \"\").replace(\"\\\"\",\"\")\n",
    "    \n",
    "    strCut = jieba.cut(str1) #分詞\n",
    "    #print(\"{}strCut:{}{}\".format(str_de,strCut,str_de)) #測試\n",
    "    \n",
    "    #去除停止詞：以list comprehension方式\n",
    "    str_list = [word for word in strCut if word not in stopword_set] \n",
    "    \n",
    "    #list轉喚回字串\n",
    "    strout = \" \".join(str_list)\n",
    "    \n",
    "    #寫回CSV檔\n",
    "    writer.writerow([row[0], row[1], row[2],row[3], row[4], row[5],row[6],strout])\n",
    "        \n",
    "csvOut.close()\n",
    "csvIn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
